#!/usr/bin/env python3
import os
import yaml
import time
import subprocess
import concurrent.futures
import random

DEBUG = True
TIMEOUT = 30  # æ€»è¶…æ—¶æ—¶é—´
TEST_URLS = [  # å¤šæµ‹è¯•æºä¿éšœå¯ç”¨æ€§
    "https://www.gstatic.com/generate_204",
    "http://cp.cloudflare.com/generate_204",
    "http://connectivitycheck.android.com/generate_204"
]
SPEED_TEST_URL = "https://speed.cloudflare.com/__down?bytes=1000000"  # 1MBæµ‹è¯•æ–‡ä»¶
MAX_WORKERS = 6  # ç²¾ç¡®æ§åˆ¶å¹¶å‘æ•°
TOP_NODES = 50
RETRY_COUNT = 2  # èŠ‚ç‚¹é‡è¯•æ¬¡æ•°

def log(message):
    """å¢å¼ºå‹æ—¥å¿—è®°å½•"""
    timestamp = time.strftime('%Y-%m-%d %H:%M:%S')
    log_msg = f"[{timestamp}] {message}"
    print(log_msg)
    with open("sub.log", "a", encoding='utf-8') as f:
        f.write(log_msg + "\n")

def test_ss(node):
    """ç²¾å‡†SSèŠ‚ç‚¹æµ‹è¯•"""
    for attempt in range(RETRY_COUNT + 1):
        try:
            # åŠ¨æ€é€‰æ‹©æµ‹è¯•URL
            test_url = random.choice(TEST_URLS)
            
            # æ„å»ºä»£ç†URL
            proxy_url = f"socks5://{node['cipher']}:{node['password']}@{node['server']}:{node['port']}"
            
            # åŸºç¡€è¿é€šæ€§æµ‹è¯•
            base_cmd = [
                'curl', '-sS',
                '--connect-timeout', '15',
                '--max-time', '20',
                '--proxy', proxy_url,
                '-o', '/dev/null',
                '-w', '%{http_code} %{time_total}',
                test_url
            ]
            
            result = subprocess.run(
                base_cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                timeout=25
            )
            
            # è§£æç»“æœ
            if result.returncode == 0 and '204' in result.stdout:
                latency = float(result.stdout.split()[1]) * 1000
                
                # çœŸå®é€Ÿåº¦æµ‹è¯•
                speed_cmd = [
                    'curl', '-s',
                    '--connect-timeout', '15',
                    '--max-time', '30',
                    '--proxy', proxy_url,
                    '-o', '/dev/null',
                    '-w', '%{speed_download}',
                    SPEED_TEST_URL
                ]
                
                speed_result = subprocess.run(
                    speed_cmd,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                    text=True,
                    timeout=30
                )
                
                if speed_result.returncode == 0:
                    speed = float(speed_result.stdout)  # bytes/sec
                    score = ( (1000/(latency+1)) * 0.4 + (speed/1024) * 0.6
                    log(f"âœ… SSéªŒè¯æˆåŠŸ {node['name']} | å»¶è¿Ÿ: {latency:.2f}ms | é€Ÿåº¦: {speed/1024:.2f}KB/s")
                    return {'node': node, 'latency': latency, 'speed': speed, 'score': score}
            
            log(f"âŒ SSæµ‹è¯•å¤±è´¥({attempt+1}æ¬¡) {node['name']} [é”™è¯¯: {result.stderr.strip()[:50]}]")
            time.sleep(2)  # é‡è¯•é—´éš”
            
        except Exception as e:
            log(f"SSæµ‹è¯•å¼‚å¸¸ {node['name']}: {str(e)}")
    
    return None

def load_nodes(sources):
    """æ™ºèƒ½åŠ è½½èŠ‚ç‚¹"""
    all_nodes = []
    for url in sources:
        try:
            result = subprocess.run(
                ['curl', '-sSL', '--retry', '3', url],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                timeout=30
            )
            data = yaml.safe_load(result.stdout)
            valid_nodes = [n for n in data.get('proxies', []) if isinstance(n, dict)]
            all_nodes.extend(valid_nodes)
            log(f"ğŸ“¥ ä» {url} åŠ è½½ {len(valid_nodes)} èŠ‚ç‚¹")
        except Exception as e:
            log(f"âŒ åŠ è½½å¤±è´¥ {url}: {str(e)}")
    return all_nodes

def main():
    log("=== èŠ‚ç‚¹è´¨é‡æ£€æµ‹ç³»ç»Ÿå¯åŠ¨ ===")
    
    # åŠ è½½èŠ‚ç‚¹æºï¼ˆå®é™…ä½¿ç”¨æ—¶æ›¿æ¢ä¸ºæ‚¨çš„è®¢é˜…æºï¼‰
    sources = [
        "https://raw.githubusercontent.com/mfbpn/tg_mfbpn_sub/refs/heads/main/trial",
        "https://backup.subscription.link/nodes.yml"
    ]
    all_nodes = load_nodes(sources)
    
    # å»é‡å¤„ç†
    seen = set()
    unique_nodes = []
    for node in all_nodes:
        key = f"{node.get('type')}_{node.get('server')}_{node.get('port')}"
        if key not in seen and node.get('type') == 'ss':  # ä»…æµ‹è¯•SSèŠ‚ç‚¹
            seen.add(key)
            unique_nodes.append(node)
    log(f"ğŸ” å¾…æµ‹SSèŠ‚ç‚¹æ•°: {len(unique_nodes)}")

    # å¹¶å‘æµ‹è¯•
    valid_nodes = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {executor.submit(test_ss, n): n for n in unique_nodes}
        
        for future in concurrent.futures.as_completed(futures):
            result = future.result()
            if result:
                valid_nodes.append(result)

    # ç»“æœå¤„ç†
    valid_nodes.sort(key=lambda x: -x['score'])
    best_nodes = valid_nodes[:TOP_NODES]
    
    # ç”Ÿæˆç»“æœæ–‡ä»¶
    os.makedirs("output", exist_ok=True)
    
    with open("output/nodes.yml", "w") as f:
        yaml.safe_dump(
            {"proxies": [n['node'] for n in best_nodes]},
            f,
            default_flow_style=False,
            allow_unicode=True
        )
    
    with open("output/speed.txt", "w") as f:
        f.write("æ’å | èŠ‚ç‚¹åç§° | å»¶è¿Ÿ(ms) | é€Ÿåº¦(KB/s) | ç»¼åˆè¯„åˆ†\n")
        f.write("-"*80 + "\n")
        for idx, node in enumerate(best_nodes, 1):
            f.write(f"{idx:2d}. {node['node']['name']} | {node['latency']:.2f} | {node['speed']/1024:.2f} | {node['score']:.2f}\n")
    
    log(f"ğŸ‰ æµ‹è¯•å®Œæˆï¼æœ‰æ•ˆèŠ‚ç‚¹: {len(best_nodes)}/{len(unique_nodes)}")

if __name__ == '__main__':
    try:
        main()
    except Exception as e:
        log(f"!!! ç³»ç»Ÿé”™è¯¯: {str(e)}")
